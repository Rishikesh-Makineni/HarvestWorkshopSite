---
tags:
  - Animal-Ecology
---

# Explanation

![Figure: Workflow of AI-Driven Animal Ecology Study](https://raw.githubusercontent.com/jennamk14/adae_model/master/images/SEC%20figures%20(1).png)
Figure 1: Workflow of AI-Driven Animal Ecology Studies


<details>
  <summary><strong>Paper Abstract</strong></summary>
  <p>
  Platforms that run artificial intelligence (AI)
  pipelines on edge computing resources are transforming the
  fields of animal ecology and biodiversity, enabling novel wildlife
  studies in animals’ natural habitats. With emerging remote sens-
  ing hardware, e.g., camera traps and drones, and sophisticated
  AI models in situ, edge computing will be more significant in
  future AI-driven animal ecology (ADAE) studies. However, the
  study’s objectives, the species of interest, its behaviors, range,
  and habitat, and camera placement affect the demand for edge
  resources at runtime. If edge resources are under-provisioned,
  studies can miss opportunities to adapt the settings of camera
  traps and drones to improve the quality and relevance of
  captured data. This paper presents salient features of ADAE
  studies that can be used to model latency, throughput objectives,
  and provision edge resources. Drawing from studies that span
  over fifty animal species, four geographic locations, and multiple
  remote sensing methods, we characterized common patterns
  in ADAE studies, revealing increasingly complex workflows
  involving various computer vision tasks with strict service
  level objectives (SLO). ADAE workflow demands will soon
  exceed individual edge devices’ compute and memory resources,
  requiring multiple networked edge devices to meet performance
  demands. We developed a framework to scale traces from prior
  studies and replay them offline on representative edge platforms,
  allowing us to capture throughput and latency data across
  edge configurations. We used the data to calibrate queuing and
  machine learning models that predict performance on unseen
  edge configurations, achieving errors as low as 19%
  </p>
</details>




